library(sf)
library(ncdf4)
library(raster)
library(rgdal)
library(ggspatial) #Requires g
1.
# DBO3 Shapefile for ROI
dbo3 <- "/Users/claregaffey/OneDrive - Clark University/R_Project/DBO3_shapefile/Dbo3.shp" %>%
st_read()
# 2.
##############################
# Sea Ice Concentration example
si <- "/Volumes/My Passport/RProject2021/SeaIce_MonthlySB2/SB2_1978_12_month.rst"
# create raster brick
var.sictif <- brick(si)#varname="chlor_a")
#project
crs(var.sictif) <- "EPSG:3413"
#crop
sicrop <- crop(x = var.sictif, y = dbo3)
# Visualize the entire file and the ROI
ggplot() +
layer_spatial(var.sictif, aes(fill = stat(band1))) +
scale_fill_continuous(na.value = NA) + layer_spatial(dbo3)
# The cropped sea ice concentration to DBO3
ggplot() +
layer_spatial(sicrop)
# Calculate the mean of DBO3 sea ice concentration for DBO3 on our sample date
cellStats(x = sicrop, stat = "mean")
# 3.
#####################
#Chlorophyll
#^^^^^^^^^^^^^^^^^^^^^^^
# This code loads in chl netcdf, converts to a raster object, reprojects it to
# match the other files(SIC, DBO3 bounding box ROI), crops it to the DBO3 ROI,
# and visualizes the data.
## Clean version of chla:
chl <- "/Volumes/My Passport/RProject2021/MODIS_chl/A20031822003212.L3m_MO_CHL.x_chlor_a.nc"
chla <- nc_open(chl)
#check out the netcdf contents
chla
# create raster brick
var.chl<-brick(chl,varname="chlor_a")
crs(var.chl)
# reproejct chla data and crop
lay1_chl <- projectRaster(var.chl[[1]], crs = crs(var.sictif)) #will only work if i plug in the index
chldbo3varlay1 <- crop(x = lay1_chl, y = dbo3)
# The projected MODIS chlorophyll and our region of interest
ggplot() +
layer_spatial(lay1_chl, aes(fill = stat(band1))) +
scale_fill_continuous(na.value = NA) +
layer_spatial(dbo3)
#the cropped DBO3 view
ggplot() +
layer_spatial(chldbo3varlay1)
NARR_dataprep <- function(NARR_brick, ROI) {
ek <- dim(NARR_brick)
time <- list()
meanlcl <- list()
counter <- 0
for (i in 1:ek[3]){
r <- subset(NARR_brick,i) %>% # running each time slice (works best)
projectRaster(crs = crs(var.sictif))  %>% #will not work with EPSG#
crop(y = ROI) #%>% # crop to the DBO3 extent
#resample(y = chldbo3varlay1) # Resamples to the chlorophyll pixel extents
#print(i) # keeps track of which layer we are on in the console
counter <-  counter + 1 # keep track of which layer we are on in the console
print(paste0(counter, " out of ", ek[3]))
time <- append(time, names(r)) # add raster name to a list
k <- cellStats(x = r, stat = "mean") # calculate a mean over ROI
meanlcl <- append(meanlcl, k) # add averaged variable to a list
}
# make a dataframe with the raster name (time) and averaged variable lists
df <- do.call(rbind, Map(data.frame, Time=time, LowCloud=meanlcl))
df$Year.month.day <-  substr(df$Time,2,11) # new column for date info
nam <- paste0(deparse(substitute(NARR_brick)), ".csv") # for file naming
# export to a csv
write.csv(df, file = paste("/Users/claregaffey/Documents/RClass/", nam),
row.names = FALSE)#here::here(paste("external/data/", nam)))
return(head(df)) # display some rows of our dataframe
}
# 4.
#####################
# Cloud data
lcl <- "/Volumes/My Passport/RProject2021/lcdc.mon.mean.nc" #Users/claregaffey/Downloads/lcdc.mon.mean.nc"#/
lcdc <- nc_open(lcl)
#check out the netcdf contents
lcdc
# create raster brick
var.nc1<-brick(lcl,varname="lcdc")
# Check out the contents
var.nc1
# reproject raster data to match the other raster datasets
lay1_clo <- projectRaster(var.nc1[[1]], crs = crs(var.sictif))#will only work if i plug in the index
# check that it reprojected
crs(lay1_clo)
# crop to DBO3 region of interest (ROI)
clodbo3varlay1 <- crop(x = lay1_clo, y = dbo3)
# The reprojected low cloud cover and our region of interest
ggplot() +
layer_spatial(lay1_clo, aes(fill = stat(band1))) +
scale_fill_continuous(na.value = NA) +
layer_spatial(dbo3)
# The cropped DBO3 ROI of our cloud layer
ggplot() +
layer_spatial(clodbo3varlay1)
## Resample to match pixels of chlorophyll raster
cloudresampled <- resample(x = clodbo3varlay1, y = chldbo3varlay1)
# Calculate the mean over our cloud
cellStats(x = clodbo3varlay1, stat = "mean")
#^^^^^^^^^^^^^^^^^^^^^^^^^^^^
# To preprocess the dataset for the regression model:
NARR_dataprep(var.nc1, dbo3)
#^^^^^^^^^^^^^^^^^^^^^^^^^^^^
# To preprocess the dataset for the regression model:
NARR_dataprep(var.nc1, dbo3)
library(sp)
library(tidyverse)
library(sf)
library(ncdf4)
library(raster)
library(rgdal)
library(ggspatial)
# DBO3 Shapefile for ROI
dbo3 <- "/Users/claregaffey/OneDrive - Clark University/R_Project/DBO3_shapefile/Dbo3.shp" %>%
st_read()
# 2.
##############################
# Sea Ice Concentration example
si <- "/Volumes/My Passport/RProject2021/SeaIce_MonthlySB2/SB2_1978_12_month.rst"
# create raster brick
var.sictif <- brick(si)#varname="chlor_a")
#project
crs(var.sictif) <- "EPSG:3413"
# and visualizes the data.
## Clean version of chla:
chl <- "/Volumes/My Passport/RProject2021/MODIS_chl/A20031822003212.L3m_MO_CHL.x_chlor_a.nc"
chla <- nc_open(chl)
#check out the netcdf contents
chla
# create raster brick
var.chl<-brick(chl,varname="chlor_a")
crs(var.chl)
# reproejct chla data and crop
lay1_chl <- projectRaster(var.chl[[1]], crs = crs(var.sictif)) #will only work if i plug in the index
chldbo3varlay1 <- crop(x = lay1_chl, y = dbo3)
NARR_dataprep <- function(NARR_brick, ROI) {
ek <- dim(NARR_brick)
time <- list()
meanlcl <- list()
counter <- 0
for (i in 1:ek[3]){
r <- subset(NARR_brick,i) %>% # running each time slice (works best)
projectRaster(crs = crs(var.sictif))  %>% #will not work with EPSG#
crop(y = ROI) #%>% # crop to the DBO3 extent
#resample(y = chldbo3varlay1) # Resamples to the chlorophyll pixel extents
#print(i) # keeps track of which layer we are on in the console
counter <-  counter + 1 # keep track of which layer we are on in the console
print(paste0(counter, " out of ", ek[3]))
time <- append(time, names(r)) # add raster name to a list
k <- cellStats(x = r, stat = "mean") # calculate a mean over ROI
meanlcl <- append(meanlcl, k) # add averaged variable to a list
}
# make a dataframe with the raster name (time) and averaged variable lists
df <- do.call(rbind, Map(data.frame, Time=time, LowCloud=meanlcl))
df$Year.month.day <-  substr(df$Time,2,11) # new column for date info
nam <- paste0(deparse(substitute(NARR_brick)), ".csv") # for file naming
# export to a csv
write.csv(df, file = paste("/Users/claregaffey/Documents/RClass/", nam),
row.names = FALSE)#here::here(paste("external/data/", nam)))
return(head(df)) # display some rows of our dataframe
}
rhu <- "/Volumes/My Passport/RProject2021/rhum.2m.mon.mean.nc"
# create raster brick
var.rhum<-brick(rhu,varname="rhum")
var.rhum
NARR_dataprep <- function(NARR_brick, ROI) {
ek <- dim(NARR_brick)
time <- list()
meanlcl <- list()
counter <- 0
for (i in 1:ek[3]){
r <- subset(NARR_brick,i) %>% # running each time slice (works best)
projectRaster(crs = crs(var.sictif))  %>% #will not work with EPSG#
crop(y = ROI) #%>% # crop to the DBO3 extent
#resample(y = chldbo3varlay1) # Resamples to the chlorophyll pixel extents
#print(i) # keeps track of which layer we are on in the console
counter <-  counter + 1 # keep track of which layer we are on in the console
print(paste0(counter, " out of ", ek[3]))
time <- append(time, names(r)) # add raster name to a list
k <- cellStats(x = r, stat = "mean") # calculate a mean over ROI
meanlcl <- append(meanlcl, k) # add averaged variable to a list
}
# make a dataframe with the raster name (time) and averaged variable lists
nam <- paste0(deparse(substitute(NARR_brick)), ".csv") # for file naming
df <- do.call(rbind, Map(data.frame, Time=time, nam=meanlcl))
df$Year.month.day <-  substr(df$Time,2,11) # new column for date info
# export to a csv
write.csv(df, file = paste("/Users/claregaffey/Documents/RClass/", nam),
row.names = FALSE)#here::here(paste("external/data/", nam)))
return(head(df)) # display some rows of our dataframe
}
# create the dataframe and exported csv
NARR_dataprep(var.rhum, dbo3)
NARR_dataprep <- function(NARR_brick, ROI) {
ek <- dim(NARR_brick)
time <- list()
meanlcl <- list()
counter <- 0
for (i in 1:ek[3]){
r <- subset(NARR_brick,i) %>% # running each time slice (works best)
projectRaster(crs = crs(var.sictif))  %>% #will not work with EPSG#
crop(y = ROI) #%>% # crop to the DBO3 extent
#resample(y = chldbo3varlay1) # Resamples to the chlorophyll pixel extents
counter <-  counter + 1 # keep track of which layer we are on in the console
print(paste0(counter, " out of ", ek[3]))
time <- append(time, names(r)) # add raster name to a list
k <- cellStats(x = r, stat = "mean") # calculate a mean over ROI
meanlcl <- append(meanlcl, k) # add averaged variable to a list
}
# make a dataframe with the raster name (time) and averaged variable lists
nam <- paste0(deparse(substitute(NARR_brick)), ".csv") # for file naming
df <- do.call(rbind, Map(data.frame, Time=time, Variable=meanlcl))
names(df)[names(df) == 'Variable'] <- nam #rename var column to match header
df$Year.month.day <-  substr(df$Time,2,11) # new column for date info
# export to a csv
write.csv(df, file = paste("/Users/claregaffey/Documents/RClass/", nam),
row.names = FALSE)#here::here(paste("external/data/", nam)))
return(head(df)) # display some rows of our dataframe
}
var.sictif
#Need SIC Loop
mystack <- stack()
files <- list.files(path="/Volumes/My Passport/RProject2021/SeaIce_MonthlySB2/",
pattern="*.rst", full.names=TRUE, recursive=FALSE)
lapply(files, function(x) {
sicbrick <- brick(x) # create a raster brick
mystack <- stack(mystack, sicbrick) #stack all of the bricks
})
mystack)
mystack
sicbrick
#Need SIC Loop
mystack <- stack()
mystack
for (x in files) {
sicbrick <- brick(x) # create a raster brick
mystack <- stack(mystack, sicbrick) #stack all of the bricks
}
var.sic
mystack
var.sic <- brick(mystack) # create a brick from the stack
var.sic
plot(var.sec[1])
plot(var.sic[1])
var.sic[1]
NARR_dataprep <- function(NARR_brick, ROI) {
ek <- dim(NARR_brick)
time <- list()
meanlcl <- list()
counter <- 0
for (i in 1:ek[3]){
r <- subset(NARR_brick,i) %>% # running each time slice (works best)
projectRaster(crs = crs(var.sictif))  %>% #will not work with EPSG#
crop(y = ROI) #%>% # crop to the DBO3 extent
#resample(y = chldbo3varlay1) # Resamples to the chlorophyll pixel extents
counter <-  counter + 1 # keep track of which layer we are on in the console
print(paste0(counter, " out of ", ek[3]))
time <- append(time, names(r)) # add raster name to a list
k <- cellStats(x = r, stat = "mean") # calculate a mean over ROI
meanlcl <- append(meanlcl, k) # add averaged variable to a list
}
# make a dataframe with the raster name (time) and averaged variable lists
nam <- paste0(deparse(substitute(NARR_brick)), ".csv") # for file naming
df <- do.call(rbind, Map(data.frame, Time=time, Variable=meanlcl))
names(df)[names(df) == 'Variable'] <- nam #rename var column to match header
df$Year.month.day <-  substr(df$Time,2,11) # new column for date info
# export to a csv
write.csv(df, file = paste("/Users/claregaffey/Documents/RClass/", nam),
row.names = FALSE)#here::here(paste("external/data/", nam)))
return(head(df)) # display some rows of our dataframe
}
# Run for the sea ice data
NARR_dataprep(var.sic, dbo3)
for (x in files) {
sicbrick <- brick(x) # create a raster brick
crs(var.sicbrick) <- "EPSG:3413"
mystack <- stack(mystack, siccrop) #stack all of the bricks
}
#^^^^^^^^^^^^^^^^^^^^^^^
# Bring in all of the sea ice time series data
mystack <- stack()
files <- list.files(path="/Volumes/My Passport/RProject2021/SeaIce_MonthlySB2/",
pattern="*.rst", full.names=TRUE, recursive=FALSE)
for (x in files) {
sicbrick <- brick(x) # create a raster brick
crs(sicbrick) <- "EPSG:3413"
mystack <- stack(mystack, siccrop) #stack all of the bricks
}
for (x in files) {
sicbrick <- brick(x) # create a raster brick
crs(sicbrick) <- "EPSG:3413"
mystack <- stack(mystack, sicbrick) #stack all of the bricks
}
mystack
var.sic <- brick(mystack) # create a brick from the stack
var.sic
NARR_dataprep <- function(NARR_brick, ROI) {
ek <- dim(NARR_brick)
time <- list()
meanlcl <- list()
counter <- 0
for (i in 1:ek[3]){
r <- subset(NARR_brick,i) %>% # running each time slice (works best)
projectRaster(crs = crs(var.sictif))  %>% #will not work with EPSG#
crop(y = ROI) #%>% # crop to the DBO3 extent
#resample(y = chldbo3varlay1) # Resamples to the chlorophyll pixel extents
counter <-  counter + 1 # keep track of which layer we are on in the console
print(paste0(counter, " out of ", ek[3]))
time <- append(time, names(r)) # add raster name to a list
k <- cellStats(x = r, stat = "mean") # calculate a mean over ROI
meanlcl <- append(meanlcl, k) # add averaged variable to a list
}
# make a dataframe with the raster name (time) and averaged variable lists
nam <- paste0(deparse(substitute(NARR_brick)), ".csv") # for file naming
df <- do.call(rbind, Map(data.frame, Time=time, Variable=meanlcl))
names(df)[names(df) == 'Variable'] <- nam #rename var column to match header
df$Year.month.day <-  substr(df$Time,2,11) # new column for date info
# export to a csv
write.csv(df, file = paste("/Users/claregaffey/Documents/RClass/", nam),
row.names = FALSE)#here::here(paste("external/data/", nam)))
return(head(df)) # display some rows of our dataframe
}
# Run for the sea ice data
NARR_dataprep(var.sic, dbo3)
nam <- deparse(substitute(var.sic))
nam[1:6]
substr(nam,1,5)
substr(nam,4,6)
substr(nam,4,7)
substr(nam,5,7)
NARR_dataprep <- function(NARR_brick, ROI) {
ek <- dim(NARR_brick)
time <- list()
meanlcl <- list()
counter <- 0
for (i in 1:ek[3]){
r <- subset(NARR_brick,i) %>% # running each time slice (works best)
projectRaster(crs = crs(var.sictif))  %>% #will not work with EPSG#
crop(y = ROI) #%>% # crop to the DBO3 extent
#resample(y = chldbo3varlay1) # Resamples to the chlorophyll pixel extents
counter <-  counter + 1 # keep track of which layer we are on in the console
print(paste0(counter, " out of ", ek[3]))
time <- append(time, names(r)) # add raster name to a list
k <- cellStats(x = r, stat = "mean") # calculate a mean over ROI
meanlcl <- append(meanlcl, k) # add averaged variable to a list
}
# make a dataframe with the raster name (time) and averaged variable lists
nam <- paste0(deparse(substitute(NARR_brick)), ".csv") # for file naming
df <- do.call(rbind, Map(data.frame, Time=time, Variable=meanlcl))
names(df)[names(df) == 'Variable'] <- substr(nam,5,8) #rename var column to match header
df$Year.month.day <-  substr(df$Time,2,11) # new column for date info
# export to a csv
write.csv(df, file = paste("/Users/claregaffey/Documents/RClass/", nam),
row.names = FALSE)#here::here(paste("external/data/", nam)))
return(head(df)) # display some rows of our dataframe
}
#^^^^^^^^^^^^^^^^^^^^^^^
# Bring in all of the chlorophyll time series data
mystack <- stack()
files <- list.files(path="/Volumes/My Passport/RProject2021/MODIS_chl/",
pattern="*.nc", full.names=TRUE, recursive=FALSE)
for (x in files) {
chlbrick <- brick(x, varname="chlor_a") # create a raster brick
mystack <- stack(mystack, chlbrick) #stack all of the bricks
}
var.chla <- brick(mystack) # create a brick from the stack
var.chla
# Run for all chlorophyll data
NARR_dataprep(var.chla, dbo3)
rhu <- "/Volumes/My Passport/RProject2021/rhum.2m.mon.mean.nc"
# create raster brick
var.rhum<-brick(rhu,varname="rhum")
win <- "/Volumes/My Passport/RProject2021/wspd.10m.mon.mean.nc"
winp <- nc_open(win)
#check out the netcdf contents
winp
# create raster brick
var.wspd<-brick(win,varname="wspd")
var.wspd
# create the dataframe and exported csv
NARR_dataprep(var.wspd, dbo3)
csv <- read.csv("/Users/claregaffey/Documents/RClass/test_xgbdata.csv")
csv
class(csv)
#______+++++++++++_________------------_______
if (!("xgboost" %in% installed.packages())) {
install.packages("xgboost")
}
library(xgboost)
library(dplyr)
head(csv)
X = csv[:,1:3]
X <-  csv[:,1:3]
X <-  csv[,1:3]
X
Y <-  csv[,4]
Y
head(Y)
head(X)
Y <-  csv[,3]
head(Y)
Y <-  csv[,4:]
Y <-  csv[,4]
head(Y)
head(csv$LowCloud)
head(csv)
head(csv$wspd)
# Run xgb.cv
cv <- xgb.cv(data = as.matrix(X), #Use as.matrix() to convert the data frame to a matrix.
label = Y, #csv$LowCloud,
nrounds = 100,
nfold = 5,
objective = "reg:linear",
eta = 0.3,
max_depth = 6,
early_stopping_rounds = 10,
verbose = 0   # silent
)
# Get the evaluation log
elog <- cv$evaluation_log
elog
head(elog)
# Determine and print how many trees minimize training and test error
elog %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))    # find the index of min(test_rmse_mean)
ntrees
ntrees.train
elog$ntrees.train
ntrees.train
ntrees.train
# Determine and print how many trees minimize training and test error
elog %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))    # find the index of min(test_rmse_mean)
# Run xgboost
lcc_xgb <- xgboost(data = as.matrix(X), # training data as matrix
label = Y,  # column of outcomes
nrounds = 22#ntrees,       # number of trees to build
objective = "reg:linear", # objective
eta = 0.3,
depth = 6,
verbose = 0  # silent
)
# Run xgboost
lcc_xgb <- xgboost(data = as.matrix(X), # training data as matrix
label = Y,  # column of outcomes
nrounds = 22,#ntrees,       # number of trees to build
objective = "reg:linear", # objective
eta = 0.3,
depth = 6,
verbose = 0  # silent
)
# Run xgb.cv
cv <- xgb.cv(data = as.matrix(X), #Use as.matrix() to convert the data frame to a matrix.
label = Y, #csv$LowCloud,
nrounds = 100,
nfold = 5,
objective = "reg:linear",
eta = 0.3,
max_depth = 6,
early_stopping_rounds = 10,
verbose = 0   # silent
)
head(csv)
# Get the evaluation log
elog <- cv$evaluation_log
head(elog)
# Determine and print how many trees minimize training and test error
elog %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))    # find the index of min(test_rmse_mean)
# Run xgboost
lcc_xgb <- xgboost(data = as.matrix(X), # training data as matrix
label = Y,  # column of outcomes
nrounds = 22,#ntrees,       # number of trees to build
objective = "reg:linear", # objective
eta = 0.3,
depth = 6,
verbose = 0  # silent
)
# Make predictions-xgb
csv$pred <- predict(lcc_xgb, as.matrix(X))
# Plot predictions (on x axis) vs actual bike rental count
ggplot(csv, aes(x = pred, y = LowCloud)) +
geom_point() +
geom_abline()
library(ggplot)
library(ggplot2)
# Plot predictions (on x axis) vs actual bike rental count
ggplot(csv, aes(x = pred, y = LowCloud)) +
geom_point() +
geom_abline()
ntrees.train
ntrees <- elog %>%
summarize(ntrees.train = which.min(train_rmse_mean))
ntrees
head(elog)
# Calculate RMSE
csv %>%
mutate(residuals = LowCloud - pred) %>%
summarize(rmse = sqrt(mean(residuals^2)))
